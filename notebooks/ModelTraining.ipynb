{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameter_rules = {\n",
    "    SVC: [\n",
    "        (\n",
    "            {},\n",
    "            {\n",
    "                \"C\": [0.5, 0.75, 1, 1.5],\n",
    "                \"kernel\": [\"linear\"],\n",
    "                \"class_weight\": [\"balanced\"],\n",
    "            },\n",
    "        ),\n",
    "        ({\"kernel\":{\"poly\"}}, {\"degree\": [2, 3, 4]}), \n",
    "        ({\"kernel\": {\"rbf\", \"sigmoid\"}}, {\"gamma\": [\"auto\"]}),\n",
    "    ],\n",
    "    KNeighborsClassifier: [\n",
    "        (\n",
    "            {},\n",
    "            {\n",
    "                \"n_neighbors\": [3, 5, 7, 9, 11, 15],\n",
    "                \"weights\": [\"uniform\", \"distance\"],\n",
    "                \"metric\": [\n",
    "                    \"cityblock\",\n",
    "                    \"cosine\",\n",
    "                    \"l1\",\n",
    "                    \"l2\",\n",
    "                    \"nan_euclidean\",\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "        ({\"metric\": [\"minkowski\"]}, {\"p\": [1, 2, 3, 4]}),\n",
    "    ],\n",
    "    RandomForestClassifier: [\n",
    "        (\n",
    "            {},\n",
    "            {\n",
    "                \"n_estimators\": [50, 100, 200, 400, 800, 1600],\n",
    "                \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "                \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "            },\n",
    "        )\n",
    "    ],\n",
    "    XGBClassifier: [\n",
    "        (\n",
    "            {},\n",
    "            {\n",
    "                \"n_estimators\": [25, 50, 100, 200, 400, 800],\n",
    "                \"grow_policy\": [\"depthwise\", \"lossguide\"],\n",
    "                \"learning_rate\": [0.01, 0.1, 1],\n",
    "            },\n",
    "        )\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracted code from PADDEL library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashableDict(dict):\n",
    "    def __hash__(self):\n",
    "        return hash(tuple(sorted(self.items())))\n",
    "\n",
    "\n",
    "def expand_rules(parameter_rules: list) -> dict:\n",
    "    \"\"\"Converts list of conditions and options to a dictionary that is easier to\n",
    "    parse.\n",
    "\n",
    "    Args:\n",
    "        parameter_rules (list): Rules to expand.\n",
    "\n",
    "    Returns:\n",
    "        dict: Expanded rules.\n",
    "    \"\"\"\n",
    "    expanded_rules = {}\n",
    "\n",
    "    for conditions, parameters in parameter_rules:\n",
    "        for values in product(*conditions.values()):\n",
    "            simple_conditions = HashableDict(\n",
    "                zip(conditions.keys(), [tuple([v]) for v in values])\n",
    "            )\n",
    "\n",
    "            if simple_conditions not in expanded_rules:\n",
    "                expanded_rules[simple_conditions] = {}\n",
    "\n",
    "            expanded_rules[simple_conditions].update(parameters)\n",
    "\n",
    "    return expanded_rules\n",
    "\n",
    "\n",
    "def matches(conditions: dict, other_conditions: dict) -> bool:\n",
    "    \"\"\"Determines if a condition dictionary matches within another.\n",
    "\n",
    "    Args:\n",
    "        conditions (dict): Conditions to match.\n",
    "        other_conditions (dict): Conditions to match with.\n",
    "\n",
    "    Returns:\n",
    "        bool: If condition matches.\n",
    "    \"\"\"\n",
    "    return conditions.items() > other_conditions.items()\n",
    "\n",
    "\n",
    "def merge_parameters(one: dict, other: dict) -> dict:\n",
    "    \"\"\"Merge parameters from one dict to another.\n",
    "\n",
    "    Args:\n",
    "        one (dict): Dict to merge into.\n",
    "        other (dict): Dict to merge from.\n",
    "\n",
    "    Returns:\n",
    "        dict: Merged dictionary.\n",
    "    \"\"\"\n",
    "    one = one.copy()\n",
    "    for key in other:\n",
    "        if key in one:\n",
    "            one[key] += other[key]\n",
    "        else:\n",
    "            one[key] = other[key]\n",
    "\n",
    "    return one\n",
    "\n",
    "\n",
    "def parse_hyper_parameters(parameter_rules: list, prefix=\"\") -> list:\n",
    "    \"\"\"Parses custom formatted parameter rules to sklearn compatible parameter grid.\n",
    "\n",
    "    Args:\n",
    "        parameter_rules (list): Parameter rules.\n",
    "        prefix (str, optional): Prefix to be used when naming the parameters. Useful when working with pipelines. Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        list: Parameter grid.\n",
    "    \"\"\"\n",
    "    parameter_rules = expand_rules(parameter_rules)\n",
    "\n",
    "    param_grid = []\n",
    "\n",
    "    for conditions in parameter_rules:\n",
    "        parameters = parameter_rules[conditions].copy()\n",
    "        for other_conditions in parameter_rules:\n",
    "            if matches(conditions, other_conditions):\n",
    "                parameters = merge_parameters(\n",
    "                    parameters, parameter_rules[other_conditions]\n",
    "                )\n",
    "\n",
    "        parameters.update({k: list(v) for k, v in conditions.items()})\n",
    "\n",
    "        param_grid.append(parameters)\n",
    "\n",
    "    # Rename to match model if using pipeline\n",
    "    for params in param_grid:\n",
    "        for key in list(params):\n",
    "            params[f\"{prefix}{key}\"] = params.pop(key)\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>date</th>\n",
       "      <th>hand</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>handedness</th>\n",
       "      <th>video_path</th>\n",
       "      <th>detection_time</th>\n",
       "      <th>lent</th>\n",
       "      <th>amp</th>\n",
       "      <th>...</th>\n",
       "      <th>angle__fourier_entropy__bins_5</th>\n",
       "      <th>angle__fourier_entropy__bins_10</th>\n",
       "      <th>angle__fourier_entropy__bins_100</th>\n",
       "      <th>angle__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>angle__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>angle__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONTROL01</td>\n",
       "      <td>15-12-2021</td>\n",
       "      <td>DCHA</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "      <td>D</td>\n",
       "      <td>C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...</td>\n",
       "      <td>20.139855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.451339</td>\n",
       "      <td>1.663059</td>\n",
       "      <td>2.762289</td>\n",
       "      <td>3.903490</td>\n",
       "      <td>4.760591</td>\n",
       "      <td>5.200384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONTROL01</td>\n",
       "      <td>15-12-2021</td>\n",
       "      <td>IZDA</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "      <td>D</td>\n",
       "      <td>C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...</td>\n",
       "      <td>20.342861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.380783</td>\n",
       "      <td>1.419083</td>\n",
       "      <td>2.237231</td>\n",
       "      <td>3.019232</td>\n",
       "      <td>3.724934</td>\n",
       "      <td>4.384708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.506679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONTROL02</td>\n",
       "      <td>03-02-2022</td>\n",
       "      <td>DCHA</td>\n",
       "      <td>M</td>\n",
       "      <td>73</td>\n",
       "      <td>D</td>\n",
       "      <td>C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...</td>\n",
       "      <td>19.951580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.510201</td>\n",
       "      <td>1.354659</td>\n",
       "      <td>2.135135</td>\n",
       "      <td>2.891662</td>\n",
       "      <td>3.517762</td>\n",
       "      <td>4.090366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONTROL02</td>\n",
       "      <td>03-02-2022</td>\n",
       "      <td>IZDA</td>\n",
       "      <td>M</td>\n",
       "      <td>73</td>\n",
       "      <td>D</td>\n",
       "      <td>C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...</td>\n",
       "      <td>20.414286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170467</td>\n",
       "      <td>0.249958</td>\n",
       "      <td>0.890642</td>\n",
       "      <td>1.681355</td>\n",
       "      <td>2.850379</td>\n",
       "      <td>4.076822</td>\n",
       "      <td>5.025139</td>\n",
       "      <td>5.576625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.398549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONTROL03</td>\n",
       "      <td>03-02-2022</td>\n",
       "      <td>DCHA</td>\n",
       "      <td>H</td>\n",
       "      <td>71</td>\n",
       "      <td>D</td>\n",
       "      <td>C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...</td>\n",
       "      <td>7.859725</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.655370</td>\n",
       "      <td>1.659209</td>\n",
       "      <td>2.757113</td>\n",
       "      <td>3.899873</td>\n",
       "      <td>4.803792</td>\n",
       "      <td>5.434160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 805 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_name        date  hand gender age handedness  \\\n",
       "0   CONTROL01  15-12-2021  DCHA      M  71          D   \n",
       "1   CONTROL01  15-12-2021  IZDA      M  71          D   \n",
       "2   CONTROL02  03-02-2022  DCHA      M  73          D   \n",
       "3   CONTROL02  03-02-2022  IZDA      M  73          D   \n",
       "4   CONTROL03  03-02-2022  DCHA      H  71          D   \n",
       "\n",
       "                                          video_path  detection_time  lent  \\\n",
       "0  C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...       20.139855     0   \n",
       "1  C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...       20.342861     1   \n",
       "2  C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...       19.951580     0   \n",
       "3  C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...       20.414286     0   \n",
       "4  C:\\Users\\Usuario\\Downloads\\VideosParkinson\\Vid...        7.859725     1   \n",
       "\n",
       "   amp  ...  angle__fourier_entropy__bins_5  angle__fourier_entropy__bins_10  \\\n",
       "0    0  ...                        0.090729                         0.136002   \n",
       "1    0  ...                        0.136002                         0.136002   \n",
       "2    0  ...                        0.090729                         0.136002   \n",
       "3    0  ...                        0.170467                         0.249958   \n",
       "4    0  ...                        0.136002                         0.181214   \n",
       "\n",
       "   angle__fourier_entropy__bins_100  \\\n",
       "0                          0.451339   \n",
       "1                          0.380783   \n",
       "2                          0.510201   \n",
       "3                          0.890642   \n",
       "4                          0.655370   \n",
       "\n",
       "   angle__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                        1.663059   \n",
       "1                                        1.419083   \n",
       "2                                        1.354659   \n",
       "3                                        1.681355   \n",
       "4                                        1.659209   \n",
       "\n",
       "   angle__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                        2.762289   \n",
       "1                                        2.237231   \n",
       "2                                        2.135135   \n",
       "3                                        2.850379   \n",
       "4                                        2.757113   \n",
       "\n",
       "   angle__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                        3.903490   \n",
       "1                                        3.019232   \n",
       "2                                        2.891662   \n",
       "3                                        4.076822   \n",
       "4                                        3.899873   \n",
       "\n",
       "   angle__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                        4.760591   \n",
       "1                                        3.724934   \n",
       "2                                        3.517762   \n",
       "3                                        5.025139   \n",
       "4                                        4.803792   \n",
       "\n",
       "   angle__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                        5.200384   \n",
       "1                                        4.384708   \n",
       "2                                        4.090366   \n",
       "3                                        5.576625   \n",
       "4                                        5.434160   \n",
       "\n",
       "   angle__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                NaN          \n",
       "1                                                NaN          \n",
       "2                                                NaN          \n",
       "3                                                NaN          \n",
       "4                                                NaN          \n",
       "\n",
       "   angle__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                        0.667853  \n",
       "1                                        1.506679  \n",
       "2                                        0.423826  \n",
       "3                                        0.398549  \n",
       "4                                        0.422913  \n",
       "\n",
       "[5 rows x 805 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load and concatenate multiple CSV files into a single DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    data (pandas.DataFrame): The concatenated DataFrame containing data from misc_df, classic_df, and fresh_df.\n",
    "    \"\"\"\n",
    "    misc_df = pd.read_csv('misc_df.csv')\n",
    "    classic_df = pd.read_csv('classic_df.csv')\n",
    "    fresh_df = pd.read_csv('fresh_df.csv')\n",
    "    data = pd.concat([misc_df, classic_df, fresh_df], axis=1)\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_value_counts():\n",
    "    \"\"\"\n",
    "    Prints the value counts for the 'lent' and 'amp' columns in the 'data' DataFrame.\n",
    "    \"\"\"\n",
    "    value_counts_lent = data['lent'].value_counts()\n",
    "    value_counts_amp = data['amp'].value_counts()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax[0].bar(value_counts_lent.index, value_counts_lent.values)\n",
    "    ax[0].set_xlabel('Class')\n",
    "    ax[0].set_ylabel('Instances')\n",
    "    ax[0].set_title('Number of instances per class in \"lent\"')\n",
    "\n",
    "    ax[1].bar(value_counts_amp.index, value_counts_amp.values)\n",
    "    ax[1].set_xlabel('Class')\n",
    "    ax[1].set_ylabel('Instances')\n",
    "    ax[1].set_title('Number of instances per class in \"amp\"')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print_value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocesses the given data by removing rows and columns based on certain conditions.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The input data to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The preprocessed data.\n",
    "    \"\"\"\n",
    "    index_to_remove = data[(data['lent'] == 4) | (data['amp'] == 4) | (data['age'] == 'XX')].index\n",
    "    data = data.drop(index_to_remove)\n",
    "    data = data[data['detection_time'] >= 15]\n",
    "    columns_to_remove = ['sample_name', 'date', 'video_path','detection_time']\n",
    "    data = data.drop(columns=columns_to_remove)\n",
    "    return data\n",
    "data=preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove=data[(data['lent']==3)].index\n",
    "data=data.drop(index_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "    \"\"\"\n",
    "    Performs label encoding and data type conversion.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The input data to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The preprocessed data.\n",
    "    \"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['hand'] = label_encoder.fit_transform(data['hand'])\n",
    "    data['gender'] = label_encoder.fit_transform(data['gender'])\n",
    "    data['handedness'] = label_encoder.fit_transform(data['handedness'])\n",
    "    data = data.drop(columns=\"angle__query_similarity_count__query_None__threshold_0.0\")\n",
    "    data['age'] = data['age'].astype(int)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encode_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>handedness</th>\n",
       "      <th>lent</th>\n",
       "      <th>amp</th>\n",
       "      <th>angle__mean_speed</th>\n",
       "      <th>angle__frequency_of_maximums</th>\n",
       "      <th>angle__frequency_of_minimums</th>\n",
       "      <th>angle__average_of_maximums</th>\n",
       "      <th>...</th>\n",
       "      <th>angle__fourier_entropy__bins_3</th>\n",
       "      <th>angle__fourier_entropy__bins_5</th>\n",
       "      <th>angle__fourier_entropy__bins_10</th>\n",
       "      <th>angle__fourier_entropy__bins_100</th>\n",
       "      <th>angle__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>angle__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>angle__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842585</td>\n",
       "      <td>0.640393</td>\n",
       "      <td>0.591132</td>\n",
       "      <td>0.629751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.451339</td>\n",
       "      <td>1.663059</td>\n",
       "      <td>2.762289</td>\n",
       "      <td>3.903490</td>\n",
       "      <td>4.760591</td>\n",
       "      <td>5.200384</td>\n",
       "      <td>0.667853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.537545</td>\n",
       "      <td>2.044839</td>\n",
       "      <td>2.135721</td>\n",
       "      <td>1.393629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.380783</td>\n",
       "      <td>1.419083</td>\n",
       "      <td>2.237231</td>\n",
       "      <td>3.019232</td>\n",
       "      <td>3.724934</td>\n",
       "      <td>4.384708</td>\n",
       "      <td>1.506679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.251043</td>\n",
       "      <td>1.744251</td>\n",
       "      <td>1.695799</td>\n",
       "      <td>0.376918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.510201</td>\n",
       "      <td>1.354659</td>\n",
       "      <td>2.135135</td>\n",
       "      <td>2.891662</td>\n",
       "      <td>3.517762</td>\n",
       "      <td>4.090366</td>\n",
       "      <td>0.423826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771708</td>\n",
       "      <td>0.940298</td>\n",
       "      <td>0.940298</td>\n",
       "      <td>0.286869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079983</td>\n",
       "      <td>0.170467</td>\n",
       "      <td>0.249958</td>\n",
       "      <td>0.890642</td>\n",
       "      <td>1.681355</td>\n",
       "      <td>2.850379</td>\n",
       "      <td>4.076822</td>\n",
       "      <td>5.025139</td>\n",
       "      <td>5.576625</td>\n",
       "      <td>0.398549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.552925</td>\n",
       "      <td>0.552925</td>\n",
       "      <td>0.638055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.125256</td>\n",
       "      <td>0.125256</td>\n",
       "      <td>0.260704</td>\n",
       "      <td>1.598268</td>\n",
       "      <td>2.589804</td>\n",
       "      <td>3.590988</td>\n",
       "      <td>4.342525</td>\n",
       "      <td>4.828759</td>\n",
       "      <td>0.698242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hand  gender  age  handedness  lent  amp  angle__mean_speed  \\\n",
       "0     0       1   71           0     0    0           0.842585   \n",
       "1     1       1   71           0     1    0           5.537545   \n",
       "2     0       1   73           0     0    0           1.251043   \n",
       "3     1       1   73           0     0    0           0.771708   \n",
       "5     1       0   71           0     1    0           0.820628   \n",
       "\n",
       "   angle__frequency_of_maximums  angle__frequency_of_minimums  \\\n",
       "0                      0.640393                      0.591132   \n",
       "1                      2.044839                      2.135721   \n",
       "2                      1.744251                      1.695799   \n",
       "3                      0.940298                      0.940298   \n",
       "5                      0.552925                      0.552925   \n",
       "\n",
       "   angle__average_of_maximums  ...  angle__fourier_entropy__bins_3  \\\n",
       "0                    0.629751  ...                        0.090729   \n",
       "1                    1.393629  ...                        0.090729   \n",
       "2                    0.376918  ...                        0.090729   \n",
       "3                    0.286869  ...                        0.079983   \n",
       "5                    0.638055  ...                        0.045395   \n",
       "\n",
       "   angle__fourier_entropy__bins_5  angle__fourier_entropy__bins_10  \\\n",
       "0                        0.090729                         0.136002   \n",
       "1                        0.136002                         0.136002   \n",
       "2                        0.090729                         0.136002   \n",
       "3                        0.170467                         0.249958   \n",
       "5                        0.125256                         0.125256   \n",
       "\n",
       "   angle__fourier_entropy__bins_100  \\\n",
       "0                          0.451339   \n",
       "1                          0.380783   \n",
       "2                          0.510201   \n",
       "3                          0.890642   \n",
       "5                          0.260704   \n",
       "\n",
       "   angle__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                        1.663059   \n",
       "1                                        1.419083   \n",
       "2                                        1.354659   \n",
       "3                                        1.681355   \n",
       "5                                        1.598268   \n",
       "\n",
       "   angle__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                        2.762289   \n",
       "1                                        2.237231   \n",
       "2                                        2.135135   \n",
       "3                                        2.850379   \n",
       "5                                        2.589804   \n",
       "\n",
       "   angle__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                        3.903490   \n",
       "1                                        3.019232   \n",
       "2                                        2.891662   \n",
       "3                                        4.076822   \n",
       "5                                        3.590988   \n",
       "\n",
       "   angle__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                        4.760591   \n",
       "1                                        3.724934   \n",
       "2                                        3.517762   \n",
       "3                                        5.025139   \n",
       "5                                        4.342525   \n",
       "\n",
       "   angle__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                        5.200384   \n",
       "1                                        4.384708   \n",
       "2                                        4.090366   \n",
       "3                                        5.576625   \n",
       "5                                        4.828759   \n",
       "\n",
       "   angle__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                        0.667853  \n",
       "1                                        1.506679  \n",
       "2                                        0.423826  \n",
       "3                                        0.398549  \n",
       "5                                        0.698242  \n",
       "\n",
       "[5 rows x 800 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slowness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   3   4   5   6   8  10  17  24  29  34  35  43  47  49  50  54  55\n",
      "  57  58  59  78  82  96 104 105 106 107 108 112 115 117 118 119 120 122\n",
      " 123 124 126 127 129 130 131 133 134 135 137 138 139 141 152 156 162 166\n",
      " 170 182 186 190 194 206 207 209 211 212 213 216 218 225 227 229 230 231\n",
      " 233 234 235 241 243 245 246 247 249 250 251 253 255 257 259 261 263 264\n",
      " 272 273 275 277 280 281 284 285 286 288 290 294 297 308 310 312 316 318\n",
      " 319 322 325 326 327 328 329 334 337 339 342 343 345 346 348 354 356 362\n",
      " 365 366 369 370 372 373 377 378 379 380 381 382 383 384 386 387 388 390\n",
      " 392 393 394 397 398 399 402 403 407 408 409 413 414 415 416 417 420 424\n",
      " 425 427 428 429 430 431 432 433 434 435 436 438 440 444 445 447 448 450\n",
      " 453 454 459 460 461 467 472 473 475 477 478 481 482 484 486 487 488 491\n",
      " 493 497 499 500 501 502 506 512 514 515 517 518 525 526 527 528 529 530\n",
      " 532 534 535 539 543 544 545 546 547 550 551 553 554 570 577 580 582 585\n",
      " 586 590 591 596 597 602 606 608 610 612 613 615 621 622 625 626 629 632\n",
      " 633 634 636 640 644 645 649 650 652 654 659 665 667 670 671 675 676 677\n",
      " 678 679 686 687 688 689 690 696 697 699 701 702 703 705 706 707 709 711\n",
      " 716 725 726 727 728 729 730 731 733 735 736 747 750 751 755 756 760 761\n",
      " 763 764 765 768 775 776 778 782 784 787 788 789 790 791]\n",
      "Doing dataset: full, model: svm_linear, features: 320\n",
      "Doing dataset: full, model: xgboost, features: 320\n",
      "Doing dataset: full, model: knn, features: 320\n",
      "Doing dataset: full, model: rf, features: 320\n",
      "Doing dataset: full, model: svm_linear, features: 320\n",
      "Doing dataset: full, model: xgboost, features: 320\n",
      "Doing dataset: full, model: knn, features: 320\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "n_folds=5\n",
    "random_state=42\n",
    "k_neighbors=3\n",
    "lent_data=data.drop(columns=['amp'])\n",
    "X=lent_data.drop(columns=['lent'])\n",
    "y=lent_data['lent']\n",
    "all_results_smote_lent=[]\n",
    "all_results_ros_lent=[]\n",
    "models = {\n",
    "    \"svm_linear\": SVC,\n",
    "    \"xgboost\":XGBClassifier,\n",
    "    \"knn\": KNeighborsClassifier,\n",
    "    \"rf\": RandomForestClassifier\n",
    "}\n",
    "smote = SMOTE(random_state=random_state,k_neighbors=k_neighbors)\n",
    "ros = RandomOverSampler(random_state=random_state)\n",
    "skf=StratifiedKFold(n_splits=n_folds)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average=\"weighted\")\n",
    "gmean_scorer = make_scorer(geometric_mean_score, average='weighted')\n",
    "index_names=X.columns[SelectKBest(k=320).fit(X, y).get_support(indices=True)]\n",
    "X=SelectKBest(k=320).fit_transform(X, y)\n",
    "X=pd.DataFrame(X,columns=index_names)\n",
    "i=0\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "    X_res_s, y_res_s = smote.fit_resample(X_train, y_train)\n",
    "    for model_name, model in models.items():\n",
    "        model_param_grid = parse_hyper_parameters(model_parameter_rules[model])\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model(),\n",
    "            param_grid=model_param_grid,\n",
    "            scoring={\n",
    "                \"f1\":f1_scorer,\n",
    "            },\n",
    "            refit=\"f1\",\n",
    "            n_jobs=10,\n",
    "            cv=StratifiedKFold(n_splits=2),\n",
    "            verbose=0\n",
    "        )\n",
    "        print(f\"Doing dataset: full, model: {model_name}, features: 320\")\n",
    "        grid.fit(X_res, y_res)\n",
    "        best_estimator = grid.best_estimator_\n",
    "        with open(f\"{model_name}_ros_lent_{i}.pkl\", \"wb\") as f:\n",
    "            pkl.dump(best_estimator, f)\n",
    "        accuracy = accuracy_scorer(best_estimator,X_test, y_test)\n",
    "        f1 = f1_scorer(best_estimator,X_test, y_test)\n",
    "        gmean = gmean_scorer(best_estimator, X_test, y_test)\n",
    "        \n",
    "        all_results_ros_lent.append({\n",
    "            \"dataset\": \"full\",\n",
    "            \"model\": model_name,\n",
    "            \"features\": 320,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"gmean\": gmean,\n",
    "            \"parameters\": grid.best_params_\n",
    "        })\n",
    "        grid.fit(X_res_s, y_res_s)\n",
    "        best_estimator = grid.best_estimator_\n",
    "        with open(f\"{model_name}_smote_lent_{i}.pkl\", \"wb\") as f:\n",
    "            pkl.dump(best_estimator, f)\n",
    "        accuracy = accuracy_scorer(best_estimator,X_test, y_test)\n",
    "        f1 = f1_scorer(best_estimator,X_test, y_test)\n",
    "        gmean = gmean_scorer(best_estimator, X_test, y_test)\n",
    "        all_results_smote_lent.append({\n",
    "            \"dataset\": \"full\",\n",
    "            \"model\": model_name,\n",
    "            \"features\": 320,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"gmean\": gmean,\n",
    "            \"parameters\": grid.best_params_\n",
    "        })\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results_smote_lent)\n",
    "df.to_csv(\"./all_results_smote_lent.csv\", index=False)\n",
    "df = pd.DataFrame(all_results_ros_lent)\n",
    "df.to_csv(\"./all_results_ros_lent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   3  10  18  24  34  35  36  37  48  59  60  78  79  81  95  96  97\n",
      " 110 111 112 121 122 123 132 134 135 136 137 139 140 143 144 146 147 148\n",
      " 150 151 152 154 155 156 158 159 160 162 163 166 167 170 174 178 179 180\n",
      " 182 183 184 186 187 188 190 191 192 195 196 199 200 204 209 210 211 213\n",
      " 216 218 219 221 222 223 231 232 235 238 239 247 277 279 282 287 289 290\n",
      " 294 295 297 298 300 301 307 308 309 310 312 314 316 318 319 321 322 324\n",
      " 327 328 329 331 332 333 335 337 339 340 341 342 343 344 347 348 349 353\n",
      " 354 355 356 357 362 363 365 366 369 371 372 373 375 378 380 381 383 385\n",
      " 387 388 394 398 400 401 402 404 405 407 409 410 411 412 414 415 416 417\n",
      " 418 419 420 422 424 425 426 427 430 437 438 439 440 441 442 443 444 445\n",
      " 446 448 449 450 451 452 453 455 459 461 462 463 465 467 468 469 471 472\n",
      " 473 475 497 498 500 501 508 509 510 512 518 519 520 521 522 525 527 528\n",
      " 529 530 532 540 541 542 544 545 546 554 555 560 563 564 565 566 571 572\n",
      " 574 577 578 581 585 586 588 589 591 593 595 597 598 599 601 602 603 604\n",
      " 605 607 608 610 611 612 613 615 616 617 620 624 625 626 627 629 630 633\n",
      " 634 636 637 639 640 642 643 646 647 648 651 652 654 655 658 659 661 663\n",
      " 665 666 667 668 670 671 678 679 689 690 696 705 707 708 709 710 712 716\n",
      " 722 728 732 734 757 758 761 763 765 766 771 775 782 786]\n",
      "Doing dataset: full, model: svm_linear, features: 320\n",
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
      "Doing dataset: full, model: xgboost, features: 320\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 46\u001b[0m\n\u001b[1;32m     34\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     35\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel(),\n\u001b[1;32m     36\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mmodel_param_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoing dataset: full, model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, features: 320\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m best_estimator \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_        \n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ros_amp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv10/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_folds=5\n",
    "random_state=42\n",
    "k_neighbors=3\n",
    "amp_data=data.drop(columns=['lent'])\n",
    "X=amp_data.drop(columns=['amp'])\n",
    "y=amp_data['amp']\n",
    "all_results_smote_amp=[]\n",
    "all_results_ros_amp=[]\n",
    "models = {\n",
    "    \"svm_linear\": SVC,\n",
    "    \"xgboost\":XGBClassifier,\n",
    "    \"knn\": KNeighborsClassifier,\n",
    "    \"rf\": RandomForestClassifier\n",
    "}\n",
    "smote = SMOTE(random_state=random_state,k_neighbors=k_neighbors)\n",
    "ros = RandomOverSampler(random_state=random_state)\n",
    "skf=StratifiedKFold(n_splits=n_folds)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average=\"weighted\")\n",
    "gmean_scorer = make_scorer(geometric_mean_score, average='weighted')\n",
    "index_names=X.columns[SelectKBest(k=320).fit(X, y).get_support(indices=True)]\n",
    "X=SelectKBest(k=320).fit_transform(X, y)\n",
    "X=pd.DataFrame(X,columns=index_names)\n",
    "i=0\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "    X_res_s, y_res_s = smote.fit_resample(X_train, y_train)\n",
    "    for model_name, model in models.items():\n",
    "        model_param_grid = parse_hyper_parameters(model_parameter_rules[model])\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model(),\n",
    "            param_grid=model_param_grid,\n",
    "            scoring={\n",
    "                \"f1\":f1_scorer,\n",
    "            },\n",
    "            refit=\"f1\",\n",
    "            n_jobs=10,\n",
    "            cv=StratifiedKFold(n_splits=2),\n",
    "            verbose=3\n",
    "        )\n",
    "        print(f\"Doing dataset: full, model: {model_name}, features: 320\")\n",
    "        grid.fit(X_res, y_res)\n",
    "        best_estimator = grid.best_estimator_        \n",
    "        with open(f\"{model_name}_ros_amp_{i}.pkl\", \"wb\") as f:\n",
    "            pkl.dump(best_estimator, f)\n",
    "\n",
    "        accuracy = accuracy_scorer(best_estimator,X_test, y_test)\n",
    "        f1 = f1_scorer(best_estimator,X_test, y_test)\n",
    "        gmean = gmean_scorer(best_estimator, X_test, y_test)\n",
    "        \n",
    "        all_results_ros_amp.append({\n",
    "            \"dataset\": \"full\",\n",
    "            \"model\": model_name,\n",
    "            \"features\": 320,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"gmean\": gmean,\n",
    "            \"parameters\": grid.best_params_\n",
    "        })\n",
    "        grid.fit(X_res_s, y_res_s)\n",
    "        best_estimator = grid.best_estimator_\n",
    "        with open(f\"{model_name}_smote_amp_{i}.pkl\", \"wb\") as f:\n",
    "            pkl.dump(best_estimator, f)\n",
    "        accuracy = accuracy_scorer(best_estimator,X_test, y_test)\n",
    "        f1 = f1_scorer(best_estimator,X_test, y_test)\n",
    "        gmean = gmean_scorer(best_estimator, X_test, y_test)\n",
    "        all_results_smote_amp.append({\n",
    "            \"dataset\": \"full\",\n",
    "            \"model\": model_name,\n",
    "            \"features\": 320,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"gmean\": gmean,\n",
    "            \"parameters\": grid.best_params_\n",
    "        })\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results_smote_amp)\n",
    "df.to_csv(\"./all_results_smote_amp.csv\", index=False)\n",
    "df = pd.DataFrame(all_results_ros_amp)\n",
    "df.to_csv(\"./all_results_ros_amp.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
